# Pharmaceutical Data Model for Databricks

A production-ready implementation of a comprehensive pharmaceutical data model in Databricks, covering the complete drug development lifecycle from discovery through commercial manufacturing.

## ğŸ“‹ Overview

This project implements a **Kimball Bus Architecture** data warehouse with three star schemas supporting:
- **Process Execution** tracking (manufacturing events and parameters)
- **Analytical Testing** (quality control, stability studies, release testing)
- **Genealogy & Traceability** (material lineage, batch genealogy, GBT compliance)

### Key Features

âœ… **23 Tables** across Bronze/Silver/Gold layers
âœ… **3 Star Schemas** with 8 conformed dimensions
âœ… **4 Self-Join Hierarchies** (material lineage, batch genealogy, process taxonomies)
âœ… **SCD Type 2** implementation on all dimension tables
âœ… **100,000+ rows** of realistic sample data
âœ… **Automated CI/CD** via GitHub Actions
âœ… **Delta Lake** format with optimization
âœ… **Medallion Architecture** (Bronze â†’ Silver â†’ Gold)

## ğŸ—ï¸ Architecture

### Data Model Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GOLD LAYER                              â”‚
â”‚               (Business-Ready Star Schemas)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Process Star          â”‚  Analytical Star  â”‚  Genealogy Star â”‚
â”‚  â€¢ Fact: Mfg Process   â”‚  â€¢ Fact: Test     â”‚  â€¢ Fact: Materialâ”‚
â”‚    Results             â”‚    Results        â”‚    Usage         â”‚
â”‚  â€¢ 11 Dimensions       â”‚  â€¢ 14 Dimensions  â”‚  â€¢ 4 Dimensions  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SILVER LAYER                             â”‚
â”‚           (Validated & Conformed with SCD Type 2)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ 8 Conformed Dimensions (Batch, Material, Sample, etc.)    â”‚
â”‚  â€¢ 2 Process Dimensions (Local & Common Hierarchies)         â”‚
â”‚  â€¢ 6 Analytical Dimensions (Test, Method, Study, etc.)       â”‚
â”‚  â€¢ 3 Genealogy Dimensions (Material Lot, Transformation, PO) â”‚
â”‚  â€¢ 1 Bridge Table (Batch Genealogy)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BRONZE LAYER                             â”‚
â”‚              (Raw Landing with Audit Columns)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Conformed Dimensions (Shared Across Star Schemas)

1. **Batch** - Manufacturing batches with genealogy hierarchy
2. **Material** - Materials with lineage (Vector â†’ Cell Line â†’ MCB â†’ WCB â†’ Protein)
3. **Sample** - Sample tracking
4. **Manufacturer** - Manufacturing sites, CMOs, testing labs
5. **Specification** - Acceptance criteria and limits
6. **Notification** - Deviations, CAPAs, investigations
7. **Document** - Batch records, COAs, SOPs, protocols
8. **Source System** - LIMS, MES, ELN, ERP systems

## ğŸš€ Quick Start

### Prerequisites

1. **Databricks Account** (Community Edition or higher)
2. **GitHub Account** with repository access
3. **GitHub Secrets** configured:
   - `DATABRICKS_HOST` - Your Databricks workspace URL
   - `DATABRICKS_TOKEN` - Personal Access Token

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/pharma-databricks-model.git
cd pharma-databricks-model

# 2. Set up environment variables
cp .env.example .env
# Edit .env with your Databricks credentials

# 3. Install dependencies locally (optional, for development)
pip install -r requirements.txt
```

### Deployment Options

#### Option A: Automated Deployment (Recommended)

1. Configure GitHub Secrets in repository settings
2. Push to `main` branch:
   ```bash
   git push origin main
   ```
3. GitHub Actions will automatically:
   - Validate code
   - Deploy DDL scripts to DBFS
   - Upload notebooks to Databricks workspace
   - Generate deployment report

#### Option B: Manual Deployment

1. **Upload files to Databricks:**
   ```bash
   # Using Databricks CLI
   databricks fs cp -r ./ddl/ dbfs:/pharma-model/ddl/ --overwrite
   databricks fs cp -r ./src/ dbfs:/pharma-model/src/ --overwrite
   databricks workspace import-dir ./notebooks /pharma-model/notebooks --overwrite
   ```

2. **Execute DDL scripts** in Databricks SQL Editor:
   - Run scripts in order: Bronze â†’ Silver â†’ Gold
   - Or import and run setup notebooks

3. **Generate sample data:**
   - Open `/pharma-model/notebooks/bronze/load_bronze_data.py`
   - Run all cells to generate realistic data

## ğŸ“Š Data Model Details

### Material Lineage Hierarchy

```
Expression Vector (Level 0)
    â”œâ”€â”€ Cell Line (Level 1)
    â”‚   â”œâ”€â”€ Master Cell Bank - MCB (Level 2)
    â”‚   â”‚   â”œâ”€â”€ Working Cell Bank - WCB (Level 3)
    â”‚   â”‚   â”‚   â””â”€â”€ Therapeutic Protein (Level 4)
```

**Example:**
```
pCDNA-CMV-Vec1
  â†’ CHO-K1-CL1
    â†’ MCB-2024-0015
      â†’ WCB-2024-0045
        â†’ mAb-Anti-PD1-TP001
```

### Batch Genealogy Scenarios

**Batch Split (1 â†’ Many):**
```
Parent Batch: BATCH-2024-00001 (1000L)
  â”œâ”€â”€ Child A: BATCH-2024-00002 (400L) - 40%
  â”œâ”€â”€ Child B: BATCH-2024-00003 (400L) - 40%
  â””â”€â”€ Child C: BATCH-2024-00004 (200L) - 20%
```

**Batch Merge (Many â†’ 1):**
```
BATCH-2024-00010 (100L) â”€â”€â”€â”
BATCH-2024-00011 (100L) â”€â”€â”€â”¼â”€â”€> BATCH-2024-00020 (300L)
BATCH-2024-00012 (100L) â”€â”€â”€â”˜
```

### Typical Workflows Supported

#### Cell Culture Process
```
Thaw â†’ Seed â†’ N-1 Expansion â†’ Production Bioreactor â†’ Harvest
```

#### Downstream Processing
```
Centrifugation â†’ Depth Filtration â†’ Protein A Chromatography
â†’ Viral Inactivation â†’ Polishing â†’ UF/DF â†’ Formulation
```

#### Stability Testing
```
Manufacturing â†’ T0 Testing â†’ 1mo â†’ 3mo â†’ 6mo â†’ 12mo â†’ 24mo â†’ 36mo
Conditions: 2-8Â°C, 25Â°C/60%RH, 40Â°C/75%RH
```

## ğŸ“– Sample Queries

### 1. Material Lineage Trace

```sql
-- Recursive query to trace material hierarchy
WITH RECURSIVE material_lineage AS (
    -- Base: Root materials (no parent)
    SELECT
        material_identity,
        material_ID,
        material_name,
        material_type,
        parent_material_identity,
        1 AS level
    FROM silver.v_dim_material_current
    WHERE parent_material_identity IS NULL

    UNION ALL

    -- Recursive: Children
    SELECT
        m.material_identity,
        m.material_ID,
        m.material_name,
        m.material_type,
        m.parent_material_identity,
        ml.level + 1
    FROM silver.v_dim_material_current m
    INNER JOIN material_lineage ml
        ON m.parent_material_identity = ml.material_identity
)
SELECT
    level,
    material_ID,
    material_name,
    material_type
FROM material_lineage
ORDER BY level, material_name;
```

### 2. Batch Genealogy with Contribution %

```sql
-- Trace batch genealogy including splits and merges
SELECT
    child.batch_ID AS child_batch,
    child.batch_status AS child_status,
    parent.batch_ID AS parent_batch,
    bg.contribution_percent,
    bg.relationship_type,
    child.batch_size AS child_size,
    parent.batch_size AS parent_size
FROM silver.bridge_batch_genealogy bg
INNER JOIN silver.v_dim_batch_current child
    ON bg.child_batch_identity = child.batch_identity
INNER JOIN silver.v_dim_batch_current parent
    ON bg.parent_batch_identity = parent.batch_identity
ORDER BY child.batch_ID, bg.sequence_order;
```

### 3. Process Execution Metrics by Batch

```sql
-- Aggregate process metrics for each batch
SELECT
    b.batch_ID,
    m.material_name,
    lp.process_step_name,
    COUNT(*) AS execution_count,
    AVG(f.yield_value) AS avg_yield,
    AVG(f.viability_percent) AS avg_viability,
    AVG(f.temperature_celsius) AS avg_temperature,
    AVG(f.pH_value) AS avg_pH
FROM gold.fact_manufacturing_process_results f
INNER JOIN silver.v_dim_batch_current b
    ON f.batch_identity = b.batch_identity
INNER JOIN silver.v_dim_material_current m
    ON f.source_material_identity = m.material_identity
INNER JOIN silver.v_dim_local_process_hierarchy_current lp
    ON f.local_process_identity = lp.local_process_identity
GROUP BY b.batch_ID, m.material_name, lp.process_step_name
ORDER BY b.batch_ID, lp.process_step_name;
```

### 4. Stability Study Results by Timepoint

```sql
-- Stability test results across timepoints
SELECT
    b.batch_ID,
    s.study_name,
    t.test_name,
    c.storage_condition,
    tp.timepoint_label,
    AVG(f.test_result) AS avg_result,
    COUNT(CASE WHEN f.oos_flag = true THEN 1 END) AS oos_count
FROM gold.fact_analytical_results f
INNER JOIN silver.v_dim_batch_current b
    ON f.batch_identity = b.batch_identity
INNER JOIN silver.v_dim_study_current s
    ON f.study_identity = s.study_identity
INNER JOIN silver.v_dim_test_current t
    ON f.test_identity = t.test_identity
INNER JOIN silver.v_dim_condition_current c
    ON f.condition_identity = c.condition_identity
INNER JOIN silver.v_dim_timepoint_current tp
    ON f.timepoint_identity = tp.timepoint_identity
WHERE s.study_type = 'Stability'
GROUP BY
    b.batch_ID, s.study_name, t.test_name,
    c.storage_condition, tp.timepoint_label, tp.timepoint_value
ORDER BY
    b.batch_ID, t.test_name, tp.timepoint_value;
```

### 5. Out-of-Specification (OOS) Investigations

```sql
-- All OOS results with investigation details
SELECT
    b.batch_ID,
    m.material_name,
    t.test_name,
    f.test_result,
    f.test_uom,
    sp.lower_limit,
    sp.upper_limit,
    n.notification_ID,
    n.notification_type,
    n.severity_level,
    n.notification_status,
    d.document_title
FROM gold.fact_analytical_results f
INNER JOIN silver.v_dim_batch_current b
    ON f.batch_identity = b.batch_identity
INNER JOIN silver.v_dim_material_current m
    ON f.source_material_identity = m.material_identity
INNER JOIN silver.v_dim_test_current t
    ON f.test_identity = t.test_identity
LEFT JOIN silver.v_dim_specification_current sp
    ON f.specification_identity = sp.specification_identity
LEFT JOIN silver.dim_notification n
    ON f.notification_identity = n.notification_identity
LEFT JOIN silver.dim_document d
    ON f.document_identity = d.document_identity
WHERE f.oos_flag = true
ORDER BY f.test_timestamp DESC;
```

More queries available in `/docs/sample_queries.md`

## ğŸ“ Project Structure

```
pharma-databricks-model/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ databricks-deploy.yml      # CI/CD pipeline
â”œâ”€â”€ ddl/
â”‚   â”œâ”€â”€ bronze/                        # 6 SQL scripts
â”‚   â”œâ”€â”€ silver/                        # 6 SQL scripts
â”‚   â””â”€â”€ gold/                          # 4 SQL scripts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_generators/               # Data generation framework
â”‚   â”œâ”€â”€ schemas/                       # PySpark schemas
â”‚   â”œâ”€â”€ transformations/               # Bronzeâ†’Silverâ†’Gold
â”‚   â””â”€â”€ main_data_generation.py        # Orchestrator
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ setup/                         # Environment setup
â”‚   â”œâ”€â”€ bronze/                        # Bronze layer notebooks
â”‚   â”œâ”€â”€ silver/                        # Silver layer notebooks
â”‚   â”œâ”€â”€ gold/                          # Gold layer notebooks
â”‚   â””â”€â”€ analysis/                      # Sample queries
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ manage_cluster.py              # Cluster automation
â”‚   â”œâ”€â”€ execute_ddl.py                 # DDL execution
â”‚   â””â”€â”€ data_quality_checks.py         # Validation
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ databricks_config.json         # Project config
â”‚   â””â”€â”€ cluster_config.json            # Cluster specs
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ data_dictionary.md             # Complete data dictionary
â”‚   â”œâ”€â”€ deployment_guide.md            # Step-by-step deployment
â”‚   â””â”€â”€ sample_queries.md              # Additional queries
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .env.example                       # Environment template
â””â”€â”€ README.md                          # This file
```

## ğŸ”§ Configuration

### Environment Variables

Create `.env` file from template:

```bash
# Databricks Connection
DATABRICKS_HOST=https://adb-xxxxxxxxxxxx.azuredatabricks.net
DATABRICKS_TOKEN=dapi_your_token_here

# Data Generation
SAMPLE_DATA_SEED=42
NUM_MATERIALS=200
NUM_BATCHES=150
NUM_SAMPLES=500
NUM_PROCESS_RESULTS=10000
NUM_ANALYTICAL_RESULTS=10000
NUM_GENEALOGY_RECORDS=8000
```

### GitHub Secrets

Configure in repository settings â†’ Secrets and variables â†’ Actions:

- `DATABRICKS_HOST` - Your Databricks workspace URL
- `DATABRICKS_TOKEN` - Personal Access Token (Scope: workspace, clusters, SQL, jobs)

## ğŸ“š Documentation

- [Data Dictionary](docs/data_dictionary.md) - Complete entity and attribute definitions
- [Deployment Guide](docs/deployment_guide.md) - Step-by-step deployment instructions
- [Sample Queries](docs/sample_queries.md) - 15+ analytical queries with explanations
- [Architecture Overview](docs/architecture.md) - Detailed architecture documentation

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Lint code
pylint src/
black src/ --check
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- Based on pharmaceutical industry best practices
- Implements Kimball dimensional modeling methodology
- Supports FDA 21 CFR Part 11 and GMP requirements
- Designed for batch genealogy traceability (GBT) compliance

## ğŸ“ Support

For issues or questions:
- Open an issue on GitHub
- Check documentation in `/docs/`
- Review sample queries in `/docs/sample_queries.md`

## ğŸ¯ Roadmap

- [ ] Add equipment master data (ISA-88)
- [ ] Implement recipe/formula management
- [ ] Add real-time monitoring dashboard
- [ ] Integrate with external LIMS/MES systems
- [ ] Add ML models for process optimization
- [ ] Implement data versioning with Delta Lake time travel

---

**Built with â¤ï¸ for the Pharmaceutical Data Science Community**
